{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Generative AI Assistant","text":""},{"location":"#overview","title":"Overview","text":"<p>This documentation was created to help clients with their RAG use cases. In this document, we will cover creating a generative AI assistant with watsonx Assistant, that includes integrations to watsonx.ai and Watson Discovery.</p> <p>You can learn more about Generative AI and watsonx in general by following these links or by navigating using the left-hand side bar.</p>"},{"location":"#sections-overview","title":"Sections Overview","text":"<p>The sections on this website are here to help you understand each component and recreate our solution as well. There are descriptions, terminology, and step-by-step walkthroughs included.</p> <ul> <li> <p>The watsonx Assistant page will go over basic terminology that will be commonly used when using the product and include a walkthrough on creating simple actions.</p> <ul> <li>The Cloud Object Storage Video URL page will allow you to complete a walthrough of uploading an item to IBM Cloud Object Storage, generating a URL for that and then using the skills gained from the watsonx Assistant page to utilizie the URL in session variables.</li> </ul> </li> <li> <p>The Watson Discovery page will cover the basic components and concepts within the product and a walkthrough on creating projects and setting up your knowledge base.</p> </li> <li> <p>The Integrations page includes a step-by-step walkthrough of how to integrate watsonx Assistant with both Watson Discovery and watsonx.ai.</p> </li> <li> <p>The watsonx.ai page discusses the main components in the platform and an overview on how to implement generative AI use cases in watsonx.ai.</p> </li> </ul>"},{"location":"generative-ai/generative-ai/","title":"Generative AI","text":""},{"location":"generative-ai/generative-ai/#what-is-it","title":"What is it?","text":"<p>Generative AI refers to the aspect of artificial intelligence technology that focuses on generating new content, from text to images and beyond, based on the training data it has been fed and current inputs it receives.</p>"},{"location":"generative-ai/generative-ai/#why-is-it-used","title":"Why is it used?","text":"<p>In this project, generative AI is crucial for crafting responses that are both contextually relevant and linguistically coherent, making interactions with the chatbots more natural and engaging for users.</p>"},{"location":"generative-ai/generative-ai/#llms","title":"LLMs","text":"<p>Large Language Models (LLMs) are a type of generative AI used to process and generate human-like text. They utilize vast amounts of data and sophisticated algorithms to understand and produce language in a way that mimics human conversation.</p>"},{"location":"generative-ai/generative-ai/#rag","title":"RAG","text":""},{"location":"generative-ai/generative-ai/#what-is-it_1","title":"What is it?","text":"<p>Retrieval Augmented Generation (RAG) combines the power of information retrieval and language generation technologies. By integrating search results into the generative process, RAG allows AI models to produce more accurate, informative, and contextually relevant responses based on a wide range of external data sources.</p>"},{"location":"generative-ai/generative-ai/#why-is-it-used_1","title":"Why is it used?","text":"<p>RAG is used to enhance the chatbot's ability to handle complex queries by fetching relevant data in real-time and generating responses that are not just based on fixed patterns or the model's pre-existing knowledge, but also on specific, current information retrieved during the interaction.</p>"},{"location":"generative-ai/generative-ai/#ibm-reference-material","title":"IBM Reference Material","text":"<p>Generative AI</p> <p>What is retrieval-augmented generation?</p> <p>IBM RAG Architecture Diagram </p> <p></p>"},{"location":"generative-ai/watsonx/","title":"watsonx","text":"<p>IBM watsonx is a powerful AI platform designed to provide advanced AI capabilities. It is built on the principles of machine learning and artificial intelligence, and is designed to help businesses and organizations make better decisions, improve operational efficiency, and create new innovative products and services.</p>"},{"location":"generative-ai/watsonx/#features-of-watsonx","title":"Features of watsonx","text":"<ul> <li> <p>Advanced AI Capabilities: watsonx provides a wide range of AI capabilities including natural language processing, machine learning, and deep learning.</p> </li> <li> <p>Scalability: watsonx is designed to scale with your business needs. Whether you are a small business or a large enterprise, watsonx can handle your AI needs.</p> </li> <li> <p>Ease of Use: watsonx is designed to be user-friendly. It provides a simple and intuitive interface that makes it easy for users to interact with the AI.</p> </li> <li> <p>Integration: watsonx can be easily integrated with other systems and platforms. This makes it easy for businesses to incorporate watsonx into their existing workflows.</p> </li> </ul>"},{"location":"generative-ai/watsonx/#use-cases-of-watsonx","title":"Use Cases of watsonx","text":"<p>watsonx can be used in a variety of industries and applications. Here are a few examples:</p> <ul> <li> <p>Healthcare: watsonx can be used to analyze patient data and provide personalized treatment recommendations.</p> </li> <li> <p>Finance: watsonx can be used to analyze financial data and provide insights for better decision making.</p> </li> <li> <p>Retail: watsonx can be used to analyze customer behavior and provide personalized shopping experiences.</p> </li> </ul> <p>For more information about watsonx, please visit the official website.</p>"},{"location":"generative-ai/watsonx/#watsonxai","title":"watsonx.ai","text":"<p>watsonx.ai serves as the backbone for advanced AI capabilities in this project, providing robust APIs and machine learning models that assist in data analysis, natural language understanding, and decision-making processes.</p>"},{"location":"generative-ai/watsonx/#watsonx-assistant","title":"watsonx Assistant","text":"<p>watsonx Assistant is the conversational AI component used to develop and manage the chatbots' dialogue systems. It enables the creation of sophisticated conversational flows and integrates seamlessly with RAG components to utilize retrieved data effectively.</p>"},{"location":"generative-ai/watsonx/#watson-discovery","title":"Watson Discovery","text":"<p>Watson Discovery is an AI-powered search technology that plays a critical role in the RAG setup. It is used to quickly sift through vast amounts of data, finding the most relevant facts and figures needed by the chatbots to inform their responses. This component ensures that data retrieval is both fast and accurate, enhancing the overall responsiveness and reliability of the chatbots.</p> <p>This documentation is designed to provide a clear understanding of the technological framework underpinning an AI Assistant, illustrating how each component contributes to their functionality and effectiveness.</p>"},{"location":"integrations/integrations/","title":"watsonx Assistant Integrations","text":""},{"location":"integrations/integrations/#overview","title":"Overview","text":"<p>Below you can follow a step-by-step walkthrough of how to integrate watsonx Assistant with Watson Discovery and watsonx.ai. These integrations will allow you to utilize your knowledge base in Watson Discovery and use watsonx.ai LLMs to receive natural language responses.</p>"},{"location":"integrations/integrations/#create-custom-watsonxai-extension-in-watsonx-assistant","title":"Create Custom watsonx.ai Extension in watsonx Assistant","text":""},{"location":"integrations/integrations/#step-1-download-openapi-file","title":"Step 1: Download OpenAPI File","text":"<p>First, download the <code>watsonx-openapi.json</code> OpenAPI file with the button below.</p> <p>OpenAPI File</p>"},{"location":"integrations/integrations/#step-2-build-custom-extension","title":"Step 2: Build Custom Extension","text":"<ol> <li> <p>Navigate back to your Watsonx Assistant to the Integrations page.    </p> </li> <li> <p>Scroll back down and click on the Build custom extension button.    </p> </li> <li> <p>Click Next and give the extension a name and description. Click Next and then upload the OpenAPI file you downloaded from the GitHub repository.    </p> </li> <li> <p>Click Next and then Finish. You should now see a Watsonx.ai custom extension. Click Add.    </p> </li> </ol>"},{"location":"integrations/integrations/#step-3-authenticate-custom-extension","title":"Step 3: Authenticate Custom Extension","text":""},{"location":"integrations/integrations/#retrieve-api-key","title":"Retrieve API Key","text":"<ol> <li> <p>Click Add again and Next. From the Authentication type drop-down select OAuth 2.0. To get this API key go to IBM Cloud and click on the Manage drop-down on the top navigation bar and select Access (IAM). </p> </li> <li> <p>Click on API keys on the left and create an API key. Make sure you save the API key for future use because you will not be able to view the API key again.</p> </li> <li> <p>Go back to the Watsonx Assistant page and paste that API key in the text box. Click Next and Finish. Your custom Watsonx.ai extension has now been created.</p> </li> </ol>"},{"location":"integrations/integrations/#create-custom-watson-discovery-extension-in-watsonx-assistant","title":"Create Custom Watson Discovery Extension in watsonx Assistant","text":""},{"location":"integrations/integrations/#step-1-download-openapi-file_1","title":"Step 1: Download OpenAPI File","text":"<ol> <li>Download the <code>watson-discover-query-openapi.json</code> OpenAPI file with the button below.</li> </ol> <p>OpenAPI File</p>"},{"location":"integrations/integrations/#step-2-build-custom-extension_1","title":"Step 2: Build Custom Extension","text":"<ol> <li> <p>Then, navigate to the <code>Integrations</code> tab on your Watsonx Assistant page.    </p> </li> <li> <p>Scroll down and click on the Build custom extension button.    </p> </li> <li> <p>Click Next and then name the extension \u201cWatson Discovery.\u201d Click Next again and then upload the OpenAPI json file that you previously downloaded from the GitHub repository.    </p> </li> <li> <p>Click Next and then Finish. You should now see a <code>Watson Discovery</code> tile. Click Add.    </p> </li> </ol>"},{"location":"integrations/integrations/#step-3-authenticate-custom-extension_1","title":"Step 3: Authenticate Custom Extension","text":"<ol> <li> <p>Click Add again and then Next. On the authentication page, select Basic auth for the authentication type. You will then need to input 3 pieces of information:</p> <ul> <li>username</li> <li>password</li> <li>discovery URL</li> </ul> <p></p> </li> <li> <p>Under username you can input <code>apikey</code></p> </li> </ol>"},{"location":"integrations/integrations/#retrieve-api-key-and-discovery-url","title":"Retrieve API Key and Discovery URL","text":"<ol> <li> <p>For the <code>password</code> and <code>discovery URL</code>, you will need to navigate to your <code>Watson Discovery</code> instance. Go to your IBM Cloud account, click on the hamburger menu in the top left, and click on Resource List.</p> <p></p> </li> <li> <p>Open up the AI/Machine Learning section and click on your discovery instance and you should see this page.</p> <p></p> </li> <li> <p>Copy both the API key and URL and paste it on the extensions page of your watsonx Assistant instance. Paste the API key into the password text box and paste the URL in the discovery URL text box at the bottom of the page</p> </li> <li> <p>Make sure that when you paste the URL into the discovery URL text box that you take out the \u201dhttps://\u201d part of the URL.</p> </li> <li> <p>Click Next, Finish, and Close. Our last step to complete the watsonx Assistant integration with watsonx.ai and Watson Discovery will require us to create and configure some actions.</p> </li> </ol>"},{"location":"integrations/integrations/#configure-discoverywatsonxai-actions","title":"Configure Discovery/watsonx.ai Actions","text":""},{"location":"integrations/integrations/#step-1-download-actions-json-file","title":"Step 1: Download Actions JSON File","text":"<ol> <li>Download the <code>discovery-watsonx-actions.json</code> file from the button below.</li> </ol> <p>Actions JSON file</p>"},{"location":"integrations/integrations/#step-2-upload-actions-json-file-to-assistant","title":"Step 2: Upload Actions JSON File to Assistant","text":"<ol> <li> <p>Go back to the watsonx Assistant page and navigate to the Actions tab from the menu on the left.</p> <p></p> </li> <li> <p>Click on the Settings icon in the top right corner.</p> <p></p> </li> <li> <p>Navigate to the Upload/Download tab and click on the box under Upload to upload the file you just downloaded from GitHub. Then, click the blue Upload button and the Upload and replace button. Finally, click Close in the top right.</p> <p></p> </li> <li> <p>You should now see 3 actions created for you from the json file you just uploaded: Generate Answer, Invoke watsonx generation API, and Search.</p> <p></p> </li> </ol> <p>You'll see a red status symbol for both the Invoke watsonx generation API and Search actions. We'll need to go into each action and fix the errors. Before we do that, let's go set some values for some of the variables created.</p>"},{"location":"integrations/integrations/#step-3-set-session-variables","title":"Step 3: Set Session Variables","text":"<ol> <li>On the left hand side under Variables click on Created by you.</li> </ol> <p>There's 2 variables that we want to change: discovery_project_id and watsonx_project_id.</p>"},{"location":"integrations/integrations/#retrieve-discovery-project-id","title":"Retrieve Discovery Project ID","text":"<ol> <li> <p>Let's click on discovery_project_id. To get the project ID, navigate to your Watson Discovery instance. Select your project that includes the documents/information needed and navigate to the Integrate and Deploy page from the menu on the left.</p> <p></p> </li> <li> <p>Go to the API information tab and copy the Project ID.</p> <p></p> </li> <li> <p>Now, go back to your watsonx Assistant instance and paste the project ID in the Initial value text box. Click Save.</p> <p></p> </li> </ol>"},{"location":"integrations/integrations/#retrieve-watsonx-project-id","title":"Retrieve watsonx Project ID","text":"<ol> <li> <p>Now, let's click on watsonx_project_id. To get this, navigate to your watsonx instance and select the project you created. Under the Manage tab you should be able to find the project ID. Copy that and go back to the watsonx Assistant page.</p> <p></p> </li> <li> <p>Paste this value into the Initial value box similar to what you did for the discovery project ID. Click Save.</p> <p></p> </li> </ol> <p>Now that we've set these variables, let's go back to our actions.</p>"},{"location":"integrations/integrations/#step-4-configure-actions","title":"Step 4: Configure Actions","text":"<ol> <li>This can be found if you click Created by you under All items.</li> </ol>"},{"location":"integrations/integrations/#search","title":"Search","text":"<ol> <li> <p>Let's step into the Search action first. Click on Search.</p> </li> <li> <p>You'll see that step 5 on the left hand side is red. Click on that step. you should see a message that Extension not fully configured.</p> <p></p> </li> <li> <p>Let's click on Edit extension under that message.</p> </li> <li> <p>For the extension, we're going to use our Watson Discovery extension. And we're going to use the Query a project operation.</p> </li> <li> <p>We should see 2 parameters for this operation: version and project_id. We're going to set version to discovery_date_version and set project_id to discovery_project_id. To reach these values to set the parameters to, click on the drop down box to the right of To and click on Session variables. You should be able to find both discovery_date_version and discovery_project_id. Once those 2 parameters have been set, click Apply.</p> <p></p> </li> <li> <p>Make sure to save by clicking the save icon in the top right. Then, exit by clicking the X in the top right as well.</p> </li> </ol>"},{"location":"integrations/integrations/#invoke-watsonx-generation-api","title":"Invoke watsonx generation API","text":"<ol> <li> <p>Now, let's go into the Invoke watsonx generation API action.</p> </li> <li> <p>You'll see that step 1 is red. Go ahead and click on that. You'll see that there's the same error messages as the other action.</p> <p></p> </li> <li> <p>Click on Edit extension.</p> </li> <li> <p>This time for the extension, we're going to use our watsonx.ai extension. And then we're going to use the Generation operation.</p> </li> <li> <p>You should see 4 parameters that we need to set. Set version to watsonx_api_version, input to model_input, model_id to model_id, and project_id to watonsx_project_id. All of these values can be found under session variables similar to before. Finally, click Apply.</p> <p></p> </li> <li> <p>Make sure to save by clicking the save icon in the top right. Then, exit by clicking the X in the top right as well.</p> </li> </ol>"},{"location":"integrations/integrations/#optional-configure-llm-model","title":"Optional: Configure LLM Model","text":"<p>If you wanted to play around with/test different models with watsonx.ai, all you need to do is go back to the variables Created by you page. The variable model_id is the one that denotes which model to use. So, if you edit that to include the provider and model version (ex. IBM and granite-13b-chat-v2) you will be able to use that model.</p>"},{"location":"watson-discovery/WatsonDiscovery/","title":"Watson Discovery Essentials","text":""},{"location":"watson-discovery/WatsonDiscovery/#overview","title":"Overview","text":"<p>IBM Watson Discovery is an AI-powered search and text analytics engine that helps you find valuable insights in your documents and data. Whether you are analyzing reports, extracting information from contracts, or conducting research, Watson Discovery can help you get answers quickly and efficiently. IBM Watson Discovery comprises several components that work together to enhance data analysis and search capabilities:</p>"},{"location":"watson-discovery/WatsonDiscovery/#components","title":"Components","text":"<ul> <li> <p>Projects: These are the spaces where you can import different types of data from various sources to query for insights or answers.</p> </li> <li> <p>Collections: This refers to the sets of documents that you upload or crawl from a connected data source. Here, unstructured text is organized into fields like author, file type, and text.</p> </li> <li> <p>Fields: These are specific attributes or metadata extracted from your documents which can be used to organize and retrieve data based on your needs.</p> </li> <li> <p>Enrichments: These are AI-driven capabilities applied to fields to identify and extract relevant information from your documents. This helps in finding answers or insights from your data.</p> </li> <li> <p>Document retrieval: This project type is focused on building an AI-powered search function to find answers within your business data.</p> </li> <li> <p>Conversational project: This enhances a chatbot's ability to answer questions by interfacing with the data processed by Watson Discovery.</p> </li> <li> <p>Content mining project: This is used to identify trends across large volumes of text-heavy business data.</p> </li> <li> <p>Cloud Native features: These include enterprise-grade security, data isolation, GDPR compliance, and support for non-regulated PII data, designed to scale in a cloud environment.</p> </li> </ul> <p>These components together enable Watson Discovery to provide a comprehensive search and analysis solution that can be integrated into various applications for advanced data understanding and insight generation.</p>"},{"location":"watson-discovery/WatsonDiscovery/#watson-discovery-walkthrough","title":"Watson Discovery Walkthrough","text":"<p>This tutorial will guide you through the key features and functionalities of IBM Watson Discovery, helping you understand how to use the platform effectively.</p> <p>Before you begin, make sure that you have a deployment(basically an account), either through IBM Cloud Pak for Data or IBM Cloud. For further information refer to this Discovery documentation</p>"},{"location":"watson-discovery/WatsonDiscovery/#step-1-sign-up-or-log-in","title":"Step 1: Sign Up or Log In","text":"<ul> <li>Visit the IBM Cloud Website. Click on \"Log In\" or \"Create an IBM Cloud account\". If you don't have an account, follow the prompts to create one. If you already have an account, enter your credentials and log in.</li> </ul>"},{"location":"watson-discovery/WatsonDiscovery/#step-2-create-a-watson-discovery-instance","title":"Step 2: Create a Watson Discovery Instance","text":"<ul> <li> <p>After logging in, click on the Catalog from the IBM Cloud dashboard. Search for \"Watson Discovery\" in the catalog search bar.</p> </li> <li> <p>Create a New Instance: Click on \"Watson Discovery\" from the search results. Click on the Create button to create a new Watson Discovery instance.</p> </li> </ul>"},{"location":"watson-discovery/WatsonDiscovery/#step-3-launch-watson-discovery","title":"Step 3: Launch Watson Discovery","text":"<p>These instructions apply to all managed deployments, including IBM Cloud Pak for Data as a Service instances. Click the Discovery instance that you created to go to the service dashboard. On the Manage page, click Launch Watson Discovery. If you're prompted to log in, provide your IBM Cloud credentials. Click Launch tool.</p>"},{"location":"watson-discovery/WatsonDiscovery/#step-4-create-a-new-project","title":"Step 4: Create a new project","text":"<p>Create a new project by clicking on the new project button. </p> <p></p> <p>The next window will let you set a project name. Then you can pick a project type from the dropdown list based on the purpose of the project.</p> <p></p> <p>The following table provides a references for selecting a project type based on the need and goal.</p> <p>Project type description:</p> Project Type Need Goal Intelligent Document Processing I want to extract data to support automation of repetitive document processing tasks. I want to understand quickly what data is extracted from my documents and improve the data by applying enrichments. Document Retrieval Which document contains the answer to my question? Find meaningful information in sources that contain a mix of structured and unstructured data, and surface it in a stand-alone enterprise search application or in the search field of a business application. Document Retrieval for Contracts Where is the part of the contract that I need for my task? Quickly extract critical information from contracts. Conversational Search I want the chatbot I'm building to use knowledge that I own. Give a virtual assistant quick access to technical information that is stored in various external data sources and document formats to answer customer questions. Content Mining I want to uncover insights I didn't know to ask about. Gain insights from pattern analysis or perform root cause analysis."},{"location":"watson-discovery/WatsonDiscovery/#step-5-create-a-collection","title":"Step 5: Create a Collection","text":"<ul> <li>Create the data collection by clicking on the Create a collection.</li> <li>Provide a name and description for your collection.</li> <li>You can add collections of data (documents) from different sources. Choose the data source type (e.g., documents, web pages, databases) and upload your data.</li> </ul> <ul> <li> <p>You can either upload Documents Manually by dragging and droping your documents into the collection or click to upload.</p> </li> <li> <p>If you have other data sources to collect the data from, you can click on the here and a new window will open and you can select the data source and follow the steps.</p> </li> </ul> <p></p> <p>For examples, let's take a look at the web crawl option. Select \"Web Crawl\" as Data Source and click \"next\".</p>"},{"location":"watson-discovery/WatsonDiscovery/#step-6-configure-web-crawl-settings","title":"Step 6: Configure Web Crawl Settings","text":"<ul> <li> <p>Set Crawl Schedule: Configure the frequency of the crawl (e.g., daily, weekly). Regular crawling ensures that your collection stays updated with the latest information from the specified website.</p> </li> <li> <p>Enter Starting URL: Input the starting URL for the web crawl. This is the initial page from which the crawler will begin extracting data.</p> </li> <li> <p>Include/Exclude Patterns: Specify URL patterns to include or exclude certain pages. This helps refine the scope of the crawl to ensure relevant data is collected.</p> </li> </ul> <p></p> <ul> <li> <p>Set Crawl Depth: Define the crawl depth to control how many levels deep the crawler should go from the starting URL. A higher crawl depth allows the crawler to follow more links and extract more data but may take longer and collect more information than needed.</p> </li> <li> <p>Enable the javascript excution: JavaScript execution can be utilized to process and analyze dynamic web content during data ingestion, allowing for the extraction of valuable information from complex, interactive web pages.</p> </li> </ul> <p></p> <ul> <li>Activate OCR: If you need to extract text out of images, you can activate the OCR option.</li> </ul> <p></p> <ul> <li> <p>After configuring the settings, click on \"Finish\" and the web crawl will start. Watson Discovery will begin to collect data from the specified web pages according to the defined parameters.</p> </li> <li> <p>Monitoring and Managing the Crawl: Check the status of your web crawl in the Watson Discovery dashboard. You can see the progress and any errors that might have occurred. If there is any errors or warnings, you can see them in the \"Warnings and errors at a glance\" section.</p> </li> </ul> <p></p> <ul> <li>Manage Crawled Data: Once the crawl is complete, you can view the collected documents in your collection. You can further enrich, query, and analyze this data using Watson Discovery\u2019s powerful tools.</li> </ul>"},{"location":"watson-discovery/WatsonDiscovery/#step-7-document-enrichments-to-data","title":"Step 7: Document Enrichments to data","text":"<p>Click the Enrichments tab. The Enrichments page shows you a list of available enrichments. Enrichments make meaningful information easier to find and return in searches. You can apply built-in enrichments to your collection to leverage powerful Natural Language Understanding models that tag terms, such as commonly known keywords.</p> <p></p> <ul> <li> <p>The Entities enrichment is applied to the collection. Entities section, Recognizes proper nouns such as people, cities, and organizations that are mentioned in the content. This enrichment is applied automatically to collections that are added to projects of the Document Retrieval type.</p> </li> <li> <p>For the Entities v2 enrichment, click 1x Selected fields. A list of available fields is displayed and the text field is selected. This selection means that the Entities enrichment was applied to content that was indexed and added to a field named text when documents from the collection were processed.</p> </li> <li> <p>From this page, you can apply new enrichments to your collection or change the fields where an enrichment is applied. A powerful feature of Discovery is that you can add your own custom enrichments, such as dictionaries, patterns, and machine learning models. When you create custom enrichments, they are listed on this page also. You can manage where they are used from here.</p> </li> <li>You are going to apply another enrichment to the collection. Find the Keywords enrichment in the list, and then click Select fields. The Keywords enrichment recognizes significant commonly-known terms in your content. Scroll through the list of fields until you find the text field, and select it.</li> <li>Click Apply changes and reprocess. While your documents are being reprocessed to look for and tag keywords, you can continue to explore the tools available for managing a collection.</li> </ul>"},{"location":"watson-discovery/WatsonDiscovery/#step-8-manage-data","title":"Step 8: Manage data","text":"<p>In the manage data section, you can view the data and search for a document. Also by clicking on the change view icon, you can customize the view of the table into whatever you like the most.</p> <p></p>"},{"location":"watson-discovery/WatsonDiscovery/#step-9-identify-field","title":"Step 9: Identify field","text":"<p>Most content from a document is indexed in the text field automatically. You might want to index certain types of content in different fields or split up large documents so that the text field contains fewer passages per document. To do so, you can teach Discovery to recognize important fields in your documents by applying a Smart Document Understanding model to your collection.</p> <p>Smart Document Understanding (SDU) is a technology that learns about the content of a document based on the document's structure. You can apply a prebuilt SDU model or create a custom SDU model.</p> <p></p> <p>To create a custom SDU model, you select the User-trained model option, and then annotate fields in your document and submit the page. Then the model learns from the provided examples and follows the pattern for the rest of the documents.</p> <p></p>"},{"location":"watson-discovery/WatsonDiscovery/#step-10-manage-fields","title":"Step 10: Manage fields","text":"<p>The Manage fields page lists the indexed fields. From here, you can include or remove fields from the index. You can also split large documents into many smaller documents.</p> <p></p>"},{"location":"watson-discovery/WatsonDiscovery/#step-11-search-the-project","title":"Step 11: Search the project","text":"<p>Click the Improve and customize icon from the navigation panel. The Improve and customize page is where you can try out queries, then add and test customizations to improve the query results for your project. A list of sample queries is displayed to help you get started with submitting test queries.</p> <p></p> <p>Click the Run search button. Query results are displayed. From one of the query results, click View passages in document. A preview of the document where the result was found is shown. Do one of the following things to explore the search result.</p> <p>Click Open advanced view. Useful summary information is displayed, such as the number of occurrences of any enrichments that are detected in the document. Select the URL entity to highlight mentions of URLs within the text.</p> <p>To see how the information from the document is stored in JSON format, click the View as menu from the view header, and select JSON. A JSON representation of the document is displayed.</p> <p>You can explore the JSON representation to see information that Discovery captured from the document. For example, if you expand the enriched_text section, and then expand the entities section, you can see mentions of entities that were recognized and tagged by the Entities enrichment.</p>"},{"location":"watson-discovery/WatsonDiscovery/#step-12-share-the-project","title":"Step 12: Share the project","text":"<p>Click Integrate and deploy from the navigation panel. From here, you can share your project with colleagues and deploy it. Follow the on-screen instructions to add a user, and then send login credentials and the provided link to your colleague.</p> <p></p> <p>After you build your own search application and are ready to deploy it, you can use prebuilt user interface components or build a custom application.</p> <p>Click API Information. From this page, you can get the project ID for your project. You need the project ID to use the Discovery API. You also need the service instance URL and API key. The credential details are available from the Manage page of your service instance in IBM Cloud. Click UI Components to find links to ready-to-use code that you can use to create a full-featured search application faster.</p>"},{"location":"watsonx-assistant/","title":"watsonx Assistant Essentials","text":""},{"location":"watsonx-assistant/#overview","title":"Overview","text":"<p>watsonx Assistant is designed to build conversational interfaces into applications, devices, or channels. It leverages natural language understanding and machine learning to enable developers to create more engaging and effective chatbots and virtual assistants.</p>"},{"location":"watsonx-assistant/#features","title":"Features","text":"<p>Actions</p> <p>Actions enable the chatbot to perform operational tasks such as making API calls, querying databases, or executing other backend processes. These are essential for dynamically interacting with external data and systems to inform responses.</p> <p>Session Variables</p> <p>Session Variables store data about the user's current session, helping to maintain context and continuity across multi-turn dialogues. They ensure that the chatbot can provide coherent and contextually relevant interactions.</p> <p>Intents</p> <p>Intents categorize the user's goals from their inputs, guiding the chatbot in understanding and responding appropriately to user requests. This component is crucial for directing the chatbot's retrieval and response strategies.</p> <p>Entities</p> <p>Entities extract and utilize specific pieces of information from user inputs, such as dates, locations, or names. They enhance the precision and relevance of the chatbot's data retrieval, which is vital for crafting detailed responses.</p> <p>Dialogues</p> <p>Dialogues manage the flow of conversation, controlling how the chatbot responds to inputs based on the recognized intents and entities, and deciding when to gather more information or conclude an interaction.</p> <p>Skills</p> <p>Skills refer to the chatbot's capabilities that are developed to handle different aspects of interactions, such as managing dialogues or integrating actions. They allow for modular enhancement and specialization of the chatbot.</p> <p>Integrations</p> <p>Integrations connect the chatbot with external systems and platforms, expanding its functionality and enabling access to additional data sources and services. This component is key to extending the chatbot's reach and utility.</p> <p>Analytics</p> <p>Analytics monitor and analyze how users interact with the chatbot, providing insights into usage patterns, effectiveness of responses, and areas for improvement. This feedback is essential for optimizing the chatbot's performance and user satisfaction.</p>"},{"location":"watsonx-assistant/#resources","title":"Resources","text":"<ul> <li> <p>IBM watsonx Assistant</p> </li> <li> <p>IBM watsonx Assistant Documentation</p> </li> <li> <p>Accessing watsonx Assistant via API call</p> </li> <li> <p>Intermediate Skill: Video URL in RAG Scenario</p> </li> <li> <p>Intermediate Skill: Connecting to Database</p> </li> </ul>"},{"location":"watsonx-assistant/#assistant-walkthrough","title":"Assistant Walkthrough","text":"<p>This is a walk-through tutorial on creating custom actions, utilizing session variables and previewing the assistant.</p>"},{"location":"watsonx-assistant/#step-1-login","title":"Step 1: Login","text":"<p>Navigate to IBM Cloud and log in to your account. Go to your watsonx Assistant instance and click the Launch watsonx Assistant button.</p> <p></p> <p>Now let's create an Assistant!</p>"},{"location":"watsonx-assistant/#step-2-create-assistant","title":"Step 2: Create Assistant","text":""},{"location":"watsonx-assistant/#creating-an-assistant-for-the-first-time","title":"Creating an assistant for the first time","text":"<p>Once you have launced your watsonx Assistant instance, you will be prompted by the following screen.</p> <p></p> <p>Give your assistant a name and choose your preferred language. Then, click Next in the top right corner.</p> <p>On the next page, select Web from the Where do you plan on deploying your assistant drop down menu. Then, in the Tell us about yourself section, fill out some info to help the assistant learn more about who is building this assistant and why it is being built so that some settings can be pre-configured. Here's a filled out example:</p> <p></p> <p>Click Next in the top right corner again.</p> <p>On the next page, you can customize some aspects of your assistant. You can change the name of the assistant, choose a dark or light theme, and change the color.</p> <p></p> <p>Once you are done customizing your assistant, click Next in the top right corner.</p> <p>On this last page, you can preview what the base assistant looks like. There are options to copy a link to the assistant that you can share with others and to change the background of the assistant's home page to emulate a website. You will be able to view this page later on as well.</p> <p></p> <p>Once you are done previewing the assistant, click Finish in the top right corner to finish creating your assistant.</p>"},{"location":"watsonx-assistant/#creating-an-additional-assistant","title":"Creating an additional assistant","text":"<p>You will then need to create a new assistant so you will press the 'Create New +' selection located at the top. This is highlighted in the image below with a red indicator:</p> <p></p> <p>Once you click the 'Create New +' selection, you will be greeted with the below pop-up window in which the application will prompt you for an Assistant name, description, as well as the desired Assistant language.</p> <p></p> <p>Below shows a filled out screen:</p> <p></p> <p>Once selecting the blue \"Create Assistant\" button on the previous screen, you should see a Success indicator at the top right portion of your screen.</p> <p></p> <p>Now it is time to create your first Action!</p>"},{"location":"watsonx-assistant/#step-3-create-action","title":"Step 3: Create Action","text":"<p>To create an action you will need to select the chat icon on the left-most part of the screen. This will take you to the general Actions page shown below where you can select the blue 'Create Action' button:</p> <p></p> <p>Once the button is selected you are able to start building an action from scratch.</p> <p></p> <p>The page below is where you are able to name your new action. This name will be the prompt that will allow the bot to understand that it needs to invoke this specific action.</p> <p></p> <p>Once named, you can go ahead and start creating the steps of your custom action. For this breif demonstration we will be using a generic \"Log-In\" script.</p> <p>This will start by having the assistant respond with an initial phrase indicating that the action has been invoked. In this case we will choose: \"Hello, do you need to log into your account?\" as shown below:</p> <p></p> <p>For this step, we want the user to have a response of Yes/No. watsonx Assistant makes this easy for us by prepopulating that User Response for us. Below shows where this can be selected:</p> <p></p> <p>Now let's create the next Step in our custom Action.</p> <p>We are going to set this step to be conditional on the response of the initial step. This can be set by selecting the \"Is taken with conditions\" dropdown. This ensures that the current step will ONLY be taken CONDITIONALLY. Please set up the step as shown below:</p> <p></p> <p>Once the condition is set, we are going to enter text for the assistant to say. In this case we are prompting the user to enter their username to ensure smooth log in.</p> <p>We will now select the User Response as free text as shown below:</p> <p></p> <p>Now we are going to create the other condition for the first step. This would be if the User selected 'No' when initially prompted.</p> <p>Once this step is set up we are going to ensure that the \"And Then\" section is set to 'End the Action'.</p> <p></p> <p>Moving on to the next step, we are going to finish up the username/password entering.</p> <p>As we did in the second step we will prompt the user to enter their information, however, this time we will do it conditionally as we only want the users password if their entered their username. This is shown in the condition section, highlighted in the image below:</p> <ul> <li>Remember this is a brief action created without database integration. This is just an example. Please to not enter your true username and password in this example.</li> </ul> <p></p> <p>We are now ready to validate the users inputs by calling those step entries in a prompt. This is shown below. You can call the step entries by selecting the function option in the 'Assistant says' section of this screen.</p> <ul> <li>Remember this is a brief action created without database integration. This is just an example. Please to not enter your true username and password in this example.</li> </ul> <p>In this step we are going to again define the user response as Yes/No.</p> <p></p> <p>Created conditionally on the previous response, we will begin an action for Logging in. This is a static example without an integrations or external API calls. Therefore we can create a static response from the Assistant for letting the user know that they are being logged in. This is a basic step shown below:</p> <p></p> <p>We will now create a step that allows the user to know that they have been logged in and the action can now end. This can be done by selecting the 'End the action' option in the \"And then\" section.</p> <p></p> <p>We will now create another conditional step, based on the response from step 5.</p> <p>This step will not have a response from the assistant and instead will send to user back to the previous steps for the user to more accurately enter their information. This can be done in the \"And then\" section in the page as shown below:</p> <p></p> <p>There you have it! You've created your first action.</p>"},{"location":"watsonx-assistant/#step-4-session-variables","title":"Step 4: Session Variables","text":"<p>Moving on to session variables.</p> <p>These Variables are important especially when dealing with user inputs such as how we did in this brief example. To navigate to this page you will select the Variables drop down and then select the Created by you option on the left side of the screen under Variables.</p> <p>Then select the blue New Variable button on the top right portion of the screen.</p> <p></p> <p>Once you've selected the blue \"New Variable\" button, you are prompted with the Session Variable creation screen.</p> <p>In this example we have two variables:</p> <ol> <li>Username</li> <li>Password</li> </ol> <p>We will create those two variables as shown below:</p> <p></p> <p>We must ensure that the Type of variable matches the Data type that we assigned in the Action. Free Text.</p> <p>For the password session variable, we recognize that this is a sensitive variable and maybe we wouldn't want that to be stored anywhere...</p> <p>Therefore, we select the Protect data stored in this variable.</p> <p></p> <p>To set these user entries to the session variables that we just created, we must set the variable values in the Action. This can be done in any step, however, to ensure that we retain the correct user information, we will do this process in Step 6 of our action, where verification of the entries has already taken place.</p> <p>This can be done as shown below in the Variable values section of the action step:</p> <p></p>"},{"location":"watsonx-assistant/#step-5-testing","title":"Step 5: Testing","text":"<p>Let's test what we created!</p> <p>Open the preview tab at the bottom right corner of the screen.</p> <p>Type \"I want to log in\" or anything that will trigger your action to be invoked.</p> <p></p> <p>Once the selection has been made you can complete the flow that we created. Verifying the information entered and doing more testing.</p> <p></p> <p>Once the flow is completed, You can check the collected session variables by selecting the function tab on the side and opening the Session variables tab. With this you can see how the username was collected and shared. Since we selected the privacy option on the password session variable, that variable was collected and hidden.</p> <p></p> <p>Now we've created an action in watsonx assistant! Try some more out and do your own testing.</p> <p>Cheers!</p>"},{"location":"watsonx-assistant/api-access/","title":"Accessing watsonx Assistant via API","text":""},{"location":"watsonx-assistant/api-access/#overview","title":"Overview","text":"<p>This page will demonstrate how to access watsonx Assistant via an API call.</p>"},{"location":"watsonx-assistant/api-access/#resources","title":"Resources","text":"<ul> <li>watsonx Assistant v2</li> </ul>"},{"location":"watsonx-assistant/api-access/#steps","title":"Steps","text":"<ol> <li> <p>Access watsonx Assistant from Resource List in the IBM Cloud Account </p> </li> <li> <p>Get API Key for watsonx Assistant from Launch webpage </p> </li> <li> <p>Get Serice Instance URL from Launch webpage </p> </li> <li> <p>Copy the Assistant ID and the Skill ID from the Assistant settings</p> <ul> <li>Head to the Homepage of your assistant:   </li> <li>Access the Assistant Settings on the bottom left corner of the page:   </li> <li>Select View details on the Assistant IDs and API details section of the page:   </li> <li>Get the required information from this pop-up window:    </li> </ul> </li> <li> <p>Obtain the Session ID from CLI CURL <pre><code>curl -X POST -u \"apikey:{apikey}\" \"{url}/v2/assistants/{environment_id}/sessions?version=2021-11-27\" \n</code></pre></p> </li> <li> <p>Get all parameters from CLI CURL <pre><code>curl -X GET -u \"apikey:{apikey}\" \"{url}/v2/assistants/{assistant_id}/skills/{skill_id}?version=2021-11-27\"\n</code></pre></p> </li> <li> <p>Run Query from CLI CURL as API call to watsonx Agent <pre><code>curl -X POST -u \"apikey:{apikey}\" --header \"Content-Type:application/json\" --data \"{\\\"input\\\": {\\\"text\\\":\n\\\"Hello\\\"}}\" \"{url}/v2/assistants/{environment_id}/sessions/{session_id}/message?version=2024-08-25\"\n</code></pre></p> </li> </ol> <p>Cheers! Now you can chat with your watsonx Assistant via API. </p>"},{"location":"watsonx-assistant/connect-database/","title":"Connecting watsonx Assistant to External Database","text":""},{"location":"watsonx-assistant/connect-database/#integrating-with-data-source-services-on-microsoft-azure","title":"Integrating with data source services on Microsoft Azure","text":"<p>Please refer to the following link.</p>"},{"location":"watsonx-assistant/connect-database/#integrating-with-db2-database-example","title":"Integrating with Db2 Database (example)","text":""},{"location":"watsonx-assistant/connect-database/#retrieve-database-service-credentials","title":"Retrieve Database Service Credentials","text":"<p>First, you will need to retrieve service credentials from your Db2 instance. Go to your Db2 instance, select the Service credentials page, and click on the New credential button in the top right.</p> <p></p> <p>Name your credentials as you like, select Manager as the role, and click Add.</p> <p></p> <p>Credentials to Note</p> <p>You will need some of the credentials that you've just created later on in the article. Open up the service credentials and note the database, hostname, port, username, and password.</p>"},{"location":"watsonx-assistant/connect-database/#create-table-in-db2","title":"Create Table in Db2","text":"<p>Navigate to the Manage section from the menu on the left and click on the Go to UI button.</p> <p></p> <p>Click on the SQL tab and paste the SQL statement from below. Click Run all.</p> <p></p> <pre><code>CREATE TABLE USER_INFO (\n  NAME VARCHAR(255),\n  EMAIL VARCHAR(255),\n  ADDRESS VARCHAR(255)\n);\n</code></pre> <p>Table Info</p> <p>This statement creates a table called USER_INFO with 3 columns: NAME, EMAIL, and ADDRESS.</p> <p>Next, navigate to the Data tab from the left hand menu. From there, select Tables from the menu on top and select the available schema. You should see the USER_INFO table and when you click on that you should see the table definition with the columns listed as well. Once we send data to the database, you will be able to view the data by coming back to this page and clicking the View data button.</p> <p></p>"},{"location":"watsonx-assistant/connect-database/#host-a-public-endpoint-for-code-snippet","title":"Host a Public Endpoint for Code Snippet","text":"<p>We will need code for the actual action to send our data to the database and an endpoint for our watsonx Assistant to hit. Use a tool that hosts your code and exposes a public endpoint. You can use the code from below. Make sure to update your database credentials on lines 7-11 and the schema on line 28.</p> <pre><code>import sys\nimport json\nimport os, ibm_db, ibm_db_dbi\nimport pandas as pd\nimport requests\ndef main(params):\n    dsn_database = \"xxxxxxx\"            # e.g. \"MORTGAGE\"\n    dsn_uid      = \"xxxxxxx\"            # e.g. \"dash104434\"\n    dsn_pwd      = \"xxxxxxx\"            # e.g. \"7dBZ3jWt9xN6$o0JiX!m\"\n    dsn_hostname = \"xxxxxxx\"            # e.g. \"Use the same IP as Web Console\"\n    dsn_port     = \"xxxxxxx\"               # e.g. \"50000\"\n    dsn_protocol = \"TCPIP\"               # i.e. \"TCPIP\"\n    dsn_driver   = \"IBM DB2 ODBC DRIVER\" # Don't change\n    dsn = (\"DRIVER={{IBM DB2 ODBC DRIVER}};\" \"DATABASE={0};\" \"HOSTNAME={1};\" \"PORT={2};\" \"PROTOCOL=TCPIP;\" \"UID={3};\" \"PWD={4};SECURITY=SSL\").format(dsn_database, dsn_hostname, dsn_port, dsn_uid, dsn_pwd)\n\n    options = { ibm_db.SQL_ATTR_AUTOCOMMIT:  ibm_db.SQL_AUTOCOMMIT_ON }\n    connection = ibm_db_dbi.connect(dsn, dsn_uid, dsn_pwd, dsn_hostname, dsn_database, options)\n    cursor = connection.cursor()\n\n    columns = ['NAME','EMAIL','ADDRESS']\n\n    # The value you want to insert\n    name = params['name']\n    email = params['email']\n    address = params['address']\n    columns_str = ', '.join(columns)\n    placeholders = ', '.join(['?'] * len(columns))\n    insertSQL = f'INSERT INTO XXXXXX.USER_INFO ({columns_str}) VALUES ({placeholders});'\n\n    # Executing the SQL query with the value to insert\n    cursor.execute(insertSQL, (name, email, address))\n    # Committing the transaction\n\n    connection.commit()\n    # Closing the cursor and connection\n\n    cursor.close()\n</code></pre> <p>This action takes 3 parameters - name, email, and address - and sends them to the database.</p> <p>Once you've saved this code snippet and found the public endpoint, take note of the endpoint as we will need this for later.</p>"},{"location":"watsonx-assistant/connect-database/#create-openapi-document","title":"Create OpenAPI Document","text":"<p>An OpenAPI document describes an API in terms of paths and operations. In OpenAPI terms, paths are endpoints (resources), such as a hotel reservation or a customer record, that your API exposes, and operations are the HTTP methods used to manipulate these paths, such as GET, POST, or DELETE.</p> <p>You can use the Swagger Editor to create and modify your OpenAPI document.</p> <p>You can use the following block of sample OpenAPI document in your Swagger Editor. I have provided it in a .json format since watsonx Assistant requires an OpenAPI document in .json format to build a custom integration.</p> <p>Make sure to update the url (line 10) and the path (line 15) to match the endpoint you noted from the previous step.</p> <pre><code>{\n  \"openapi\": \"3.0.3\",\n  \"info\": {\n    \"title\": \"Swagger Db2 WA Extensions\",\n    \"description\": \"This is a Swagger Connecting WA to a Db2 using Cloud Function\",\n    \"version\": \"1.0.0\"\n  },\n  \"servers\": [\n    {\n      \"url\": \"https://xxxxxxxx\",\n      \"description\": \"Dallas, USA\"\n    }\n  ],\n  \"paths\": {\n    \"/xxxxx/xxxxx/xxxxx.json\": {\n      \"post\": {\n        \"parameters\": [],\n        \"summary\": \"Send user info\",\n        \"description\": \"Send info from user to db2 database\",\n        \"operationId\": \"sendUserInfo\",\n        \"requestBody\": {\n          \"description\": \"Payload to send user info to db2 database.\",\n          \"content\": {\n            \"application/json\": {\n              \"schema\": {\n                \"type\": \"object\",\n                \"properties\": {\n                  \"name\": {\n                    \"type\": \"string\",\n                    \"description\": \"user name\"\n                  },\n                  \"email\": {\n                    \"type\": \"string\",\n                    \"description\": \"user email\"\n                  },\n                  \"address\": {\n                    \"type\": \"string\",\n                    \"description\": \"user address\"\n                  }\n                }\n              }\n            }\n          },\n          \"required\": true\n        },\n        \"responses\": {\n          \"200\": {\n            \"description\": \"Successful operation.\",\n            \"content\": {\n              \"application/json\": {\n                \"schema\": {\n                  \"type\": \"object\",\n                  \"properties\": {\n                    \"user_info\": {\n                      \"type\": \"string\"\n                    }\n                  }\n                }\n              }\n            }\n          },\n          \"405\": {\n            \"description\": \"Invalid input.\"\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre> <p>Request Body Properties</p> <p>For the requestBody section (starting on line 21), you can see that there are 3 \u201cproperties\u201d defined here</p> <ul> <li>name: a string (line 28)</li> <li>email: a string (line 32)</li> <li>address: a string (line 36)</li> </ul> <p>They are required parameters that the user will input when they interact with watsonx Assistant.</p>"},{"location":"watsonx-assistant/connect-database/#integrating-custom-extenstion-in-watsonx-assistant","title":"Integrating Custom Extenstion in watsonx Assistant","text":"<p>Go to your watsonx Assistant instance. Navigate to the Integrations tab from the menu on the left-hand side of the page.</p> <p></p> <p>From the integrations page, scroll down to the Extensions section and click on the Build custom extension button.</p> <p></p> <p>On the Get started screen, click the Next button in the top right corner of the screen to get to the Basic information section. Name your extension, give it a description, and click Next.</p> <p></p> <p>On the next page, upload the OpenAPI file you created from the previous steps.</p> <p></p> <p>Click Finish in the top right corner.</p> <p>You will see that the extension you just built is now under the Extensions section. Click on Add on the bottom right corner of the tile. On the next pop-up screen, click the Add button.</p> <p></p> <p>On the Get started screen, click on Next in the top right corner to get to the next screen. Make sure your server is correct, and click on Next.</p> <p></p> <p>On the \u201cReview operations\u201d screen, click on \u201cFinish\u201d to have the extension added to your Assistant.</p> <p></p>"},{"location":"watsonx-assistant/connect-database/#create-action-in-watsonx-assistant","title":"Create Action in watsonx Assistant","text":"<p>Now that we've created the extension, let's go and create the action that will use this extension to send the user info variables from watsonx Assistant to the database.</p> <p></p> <p>First, we'll want to create the variables that we need to send over to store in the database: name, email, and address.</p> <p>To create variables, we'll need to go to Created by you under Variables.</p> <p></p> <p>Click on New variable in the top right corner to create our first variable.</p> <p>Fill in the Name and select the Type as well for our name variable that is going to be accepted as Free text. Click Save to create the variable.</p> <p></p> <p>Now, repeat this step 2 times but for the other variables that we need: email and address.</p> <p></p> <p></p> <p>Now, navigate back to the action page.</p> <p></p> <p>Click on New action in the top right corner to create our action. Select Start from scratch for how we want to build our action.</p> <p>In the following pop up box, regarding how to start the interaction, we can enter \"user info\" as the input the user would type to begin this interaction. This prompt to start the interaction can be changed later on as well. Click Save.</p> <p></p> <p>Click on Step 1, in this step we would ask the user what the user's name is under Assistant says. Names should be accepted as free text (string), so click on Define customer response and select Free text from the list.</p> <p></p> <p>Use the blue New step button to create the second step. Before the Assistant does anything in the second step, we should make sure it collects the user\u2019s response for what the user's name is from the previous step. Click on Set variable values in the top right corner, Set new value, and click on Session variables.</p> <p></p> <p>Under Session variables, choose name from the list, and in the To field, click on Action variables and select the question you asked the user in the first step.</p> <p></p> <p>Now that we have saved the user\u2019s name as a variable, we also want to know what their email is. Under Assistant says, ask them what their email is. Under Define customer response, select Free text (similar to what you did in step 1).</p> <p></p> <p>Use the blue New step button to create the third step. Similar to the second step, we should make sure it collects the user\u2019s response for what the user's email is from the previous step. Click on Set variable values in the top right corner, Set new value, and click on Session variables. Set name to the Action variable from the question you asked the user in the second step.</p> <p></p> <p>Repeat the same steps for the third and final variable: address.</p> <p></p> <p></p> <p>Now, we'll create a new step to send our set variables to be stored into the database. So, create a new step as you did before. Under And then, select \"Continue to next step\" and change it to \"Use an extension\".</p> <p></p> <p>In the following pop up, select the following options. Under Extension, select the custom extension we created \"user-info-extension\". Under Operation, select the one operation we listed in the OpenAPI file \"Send user info\". And then, under Optional parameters, set each parameter to the variables we just in the previous steps (name, email, and address). Click Apply.</p> <p></p> <p>Great! Now, we have the extension set up to send the acquired data to our database.</p> <p>If you want, you can test the extension by clicking the Preview button in the bottom right corner. Make sure to use the phrase we set to prompt this action to begin (we set the prompt as \"user info\" but you can change it to whatever you want).</p>"},{"location":"watsonx-assistant/video-url/","title":"Uploading Video Response in watsonx Assistant","text":""},{"location":"watsonx-assistant/video-url/#overview","title":"Overview","text":"<p>This page will demonstrate how to upload a video to Cloud Object Storage (COS), generate a URL for the uploaded video, as well as how to use it within a RAG scenario in the watsonx Assistant UI.</p>"},{"location":"watsonx-assistant/video-url/#resources","title":"Resources","text":"<ul> <li>Cloud Object Storage</li> <li>Cloud Object Storage Documentation</li> </ul>"},{"location":"watsonx-assistant/video-url/#high-level-steps","title":"High level steps:","text":"<ol> <li> <p>Get access to COS</p> <ul> <li>The Seller or CSM associated with your account should be able to direct you in how to obtain access</li> </ul> </li> <li> <p>Uploaded video to Cloud Object Storage</p> </li> <li> <p>Generate a pre-signed URL</p> </li> <li> <p>Place generated URL within Knowledgebase Document</p> <ul> <li>This step will vary based on what type of document you are uploading. For this walkthrough we will be using a Microsoft PowerPoint document</li> <li>Please see the Watson Discovery documentation section for instructions on uploading those files </li> </ul> </li> <li> <p>Update the Return parameter in the search extension within watsonx Assistnat</p> <ul> <li>Please see the Integrations documentation section for instructions on integrating watsonx Assistant with the knowledgebase</li> </ul> </li> <li> <p>Create a Session Variable for the URL</p> <ul> <li>Please see the watsonx Assistant walkthrough for more information on creating session variables</li> </ul> </li> <li> <p>Create an iframe embedding with the Session Variable as Source</p> </li> </ol>"},{"location":"watsonx-assistant/video-url/#cos-walthrough","title":"COS Walthrough","text":""},{"location":"watsonx-assistant/video-url/#step-1-cloud-object-storage-instance","title":"Step 1: Cloud Object Storage Instance","text":"<p>Once you have obtained your Cloud Object Storage Instance, you may access the instance through the Resource List in your IBM Cloud Account.  Please select on the instance as shown in the screen capture below:</p> <p></p>"},{"location":"watsonx-assistant/video-url/#step-2-create-bucket","title":"Step 2: Create Bucket","text":"<p>Once you have selected the instance, you must create a bucket. Please select the Create Bucket + button.</p> <p></p>"},{"location":"watsonx-assistant/video-url/#step-3-custom-bucket","title":"Step 3: Custom Bucket","text":"<p>This step may vary based on what the Seller or CSM tied to your account tells you. For this walkthrough example we will be going with a Custom Bucket. Please select the Create a Custom Bucket option.</p> <p></p>"},{"location":"watsonx-assistant/video-url/#step-4-name-bucket","title":"Step 4: Name Bucket","text":"<p>Please add a name to the Cloud Object Storage Bucket within your instance. The specific configuration of your bucket may vary based on what the Seller or CSM tied to your account tells you. For this example we will leave the configurations as default. Please select Create Bucket at the botton right of the screen once named.</p> <p></p>"},{"location":"watsonx-assistant/video-url/#step-5-selecting-bucket","title":"Step 5: Selecting Bucket","text":"<p>Once you have created your bucket you will see it within your instance. Please select the custom bucket that was created in the brevious screen.</p> <p></p>"},{"location":"watsonx-assistant/video-url/#step-6-upload-files","title":"Step 6: Upload Files","text":"<p>In this step, you will upload the files that you want to be stored in COS. Please drag and drop your files to the grey box area. In this walkthrough example we are using a watsonx Video. </p> <p></p>"},{"location":"watsonx-assistant/video-url/#step-7-endpoints","title":"Step 7: Endpoints","text":""},{"location":"watsonx-assistant/video-url/#endpoint-url","title":"Endpoint URL","text":"<p>Please select the Endpoints on the far left side of the screen. On this page, you will find the endpoint URLs which you will use in a later step of this example walkthrough.</p> <p></p>"},{"location":"watsonx-assistant/video-url/#step-8-api-key","title":"Step 8: API Key","text":"<p>Please scroll down to the bottom of the endpoint page and select the Get Credentials button on the Get and API Key option.</p> <p></p>"},{"location":"watsonx-assistant/video-url/#step-9-service-credentials","title":"Step 9: Service Credentials","text":"<p>Once you have entered the credential page, you should select New Credential in order to obtain keys that are vital for steps below.</p> <p></p>"},{"location":"watsonx-assistant/video-url/#step-10-hmac-credentials","title":"Step 10: HMAC Credentials","text":"<p>When creating the Service Credentials, it is important to Include HMAC Credentials as these are the important keys needed for generating the URL. Select Add once the toggle for HMAC credentials is selected.</p> <p></p>"},{"location":"watsonx-assistant/video-url/#step-11-obtaining-keys","title":"Step 11: Obtaining Keys","text":"<p>Once created, you will be able to see the credential in the Service Credential page and use the drop down to see the full creadentials.</p> <p></p>"},{"location":"watsonx-assistant/video-url/#url-walkthrough","title":"URL Walkthrough","text":""},{"location":"watsonx-assistant/video-url/#step-12-generating-pre-signed-url","title":"Step 12: Generating Pre-Signed URL","text":""},{"location":"watsonx-assistant/video-url/#locate-documentation","title":"Locate Documentation","text":"<p>From this step you will be able to locate code that will allow you to generate a URL from the specified item in your COS bucket.</p>"},{"location":"watsonx-assistant/video-url/#resource","title":"Resource","text":"<ul> <li>Generating a pre-signed URL</li> </ul>"},{"location":"watsonx-assistant/video-url/#copy-code","title":"Copy Code","text":"<p>From the above site, you will have several options of creating a URL, in this example walkthrough we will be using python.</p> <pre><code>import ibm_boto3\nimport os\n\nbucket_name = '&lt;bucekt name&gt;'\nkey_name = '&lt;object key name&gt;'\nhttp_method = 'get_object'\nexpiration = 600  # time in seconds, default:600\n\naccess_key = '&lt;COS_HMAC_ACCESS_KEY_ID&gt;'\nsecret_key = '&lt;COS_HMAC_SECRET_ACCESS_KEY&gt;'\n# Current list avaiable at https://control.cloud-object-storage.cloud.ibm.com/v2/endpoints\ncos_service_endpoint = 'https://s3.&lt;region&gt;.cloud-object-storage.appdomain.cloud'\n\ncos = ibm_boto3.client(\"s3\",\n                       aws_access_key_id=access_key,\n                       aws_secret_access_key=secret_key,\n                       endpoint_url=cos_service_endpoint\n                       )\n\nsignedUrl = cos.generate_presigned_url(http_method, Params={\n                                       'Bucket': bucket_name, 'Key': key_name}, ExpiresIn=expiration)\nprint(\"presigned download URL =&gt;\" + signedUrl)\n</code></pre> <p>Copy this code and save it in a python file to run. </p> <p>Utilize the Service Credentials and Endpoint URL created/located in previous steps to fill in the specified variables. Please notes that key_name refers to the item that you wish to generate a URL for. The expiration date can be bypassed by utilizing a public bucket. More information within the documentation referenced above.</p> <p>Run the python file. The output will be a URL. </p> <p>Output example: https://s3.us-south.cloud-object-storage.appdomain.cloud/BUCKETNAME/KEYNAME?AWSAccessKeyId=ACCESSKEYID (link is expired)</p>"},{"location":"watsonx-assistant/video-url/#metadata-walkthrough","title":"Metadata Walkthrough","text":""},{"location":"watsonx-assistant/video-url/#step-13-locate-document-file-properties","title":"Step 13: Locate Document File Properties","text":"<p>Please open the document you wish to associate generated URL with. Once this is done select File in the corner. As specified in an earlier section, the file type may be different based on what you are doing within your organization. This example uses a Microsoft PowerPoint document. </p> <p></p>"},{"location":"watsonx-assistant/video-url/#step-14-paste-into-properties","title":"Step 14: Paste into Properties","text":"<p>Please open the properties of the desired file from the File section of the toolbar.</p> <p></p> <p>Paste the Generated URL in the subject of the properties panel for the document you wish to associate the generated URL with. </p> <p></p> <p>Once this step is complete you can upload this document to your knowledgebase. For instructions on that please refer to the Watson Discovery section of this documentation.</p>"},{"location":"watsonx-assistant/video-url/#utilizing-url-walkthrough","title":"Utilizing URL Walkthrough","text":""},{"location":"watsonx-assistant/video-url/#step-15-return-alteration","title":"Step 15: Return Alteration","text":"<p>Within your search extension configuration in watsonx Assistant, please update the Return Parameter to include the extracted_metadata variable. This will allow for a session variable to pick up the URL which was pasted in the metadata of the document.</p> <p></p>"},{"location":"watsonx-assistant/video-url/#step-16-session-variable-asignment","title":"Step 16: Session Variable Asignment","text":"<p>Please create a session variable for this URL. In this example the variable is called 'video_url'. For information on creating a session variable please see the watsonx Assistant section of this documentation. </p> <p>Assign the extracted_metadata subject to that session variable as shown below:</p> <p></p> <p>The Expression code is shown below. This code may change based on where the URL was put within the metadata and how the document was uploaded to the database.</p> <pre><code>${search_results}.get(0).extracted_metadata.subject\n</code></pre> <p>This assigns the generated URL to the created 'video_url' session variable.</p>"},{"location":"watsonx-assistant/video-url/#step-17-display-url","title":"Step 17: Display URL","text":"<p>In whichever way suits your business needs, please utilize the URL with an action in watsonx Assisant.</p> <p></p>"},{"location":"watsonx-assistant/video-url/#step-18-iframe-embedding","title":"Step 18: iframe Embedding","text":"<p>Ensure that the 'video_url' session variable is set as the source of the iframe video embedding.</p> <p></p> <p>See JSON below:</p> <pre><code>{\n  \"generic\": [\n    {\n      \"title\": \"\",\n      \"source\": \"${video_url}\",\n      \"alt_text\": \"\",\n      \"description\": \"\",\n      \"response_type\": \"video\",\n      \"channel_options\": {\n        \"chat\": {\n          \"dimensions\": {\n            \"base_height\": 180\n          }\n        }\n      }\n    }\n  ]\n}\n</code></pre> <p>Please note that this example is a walkthrough and not meant to be a fully built out solution. This walkthrough demonstrates one of many ways to accomplish the task of utilizing a URL of an item hosted on IBM COS. </p> <p>Some of these tasks can be automated through code.</p>"},{"location":"watsonx.ai/watsonx/","title":"watsonx AI Essentials (Getting started with Generative AI)","text":""},{"location":"watsonx.ai/watsonx/#overview","title":"Overview","text":"<p>IBM\u00ae watsonx.ai\u2122 AI studio is part of the IBM watsonx\u2122 AI and data platform, bringing together new generative AI (gen AI) capabilities powered by foundation models and traditional machine learning (ML) into a powerful studio spanning the AI lifecycle. Tune and guide models with your enterprise data to meet your needs with easy-to-use tools for building and refining performant prompts. With watsonx.ai, you can build AI applications in a fraction of the time and with a fraction of the data. watsonx.ai offers:</p> <ul> <li>Multi-model variety and flexibility: Choose from IBM-developed, open-source and third-party models, or bring your own model.</li> <li>Differentiated client protection: IBM stands behind IBM-developed models and indemnifies the client against third-party IP claims.</li> <li>End-to-end AI governance: Enterprises can scale and accelerate the impact of AI with trusted data across the business, using data wherever it resides.</li> <li>Hybrid, multi-cloud deployments: IBM provides the flexibility to integrate and deploy your AI workloads into your hybrid-cloud stack of choice.</li> </ul>"},{"location":"watsonx.ai/watsonx/#features","title":"Features","text":"<ul> <li> <p>Foundation Models: watsonx.ai includes a range of pre-deployed large language models, both IBM proprietary and open-source models from platforms like Hugging Face. These models are designed for a variety of generative AI tasks, and users can select and tune models to fit specific use cases.</p> </li> <li> <p>Prompt Lab: This tool allows users to quickly experiment with AI tasks using a minimal number of labeled examples. It's part of the studio's user-friendly interface that facilitates rapid prototyping and testing of AI models.</p> </li> <li> <p>Tuning Studio: Here, users can customize foundation models with their own data. This feature supports efficient, low-cost adaptation of models for specific enterprise needs, utilizing state-of-the-art fine-tuning techniques developed by IBM Research.</p> </li> <li> <p>Synthetic Data Generator: Recently launched, this tool helps users create artificial tabular data sets. It's designed to assist in generating insights for AI model training, enhancing decision-making processes while minimizing risk.</p> </li> <li> <p>Hybrid Cloud Tools: watsonx.ai operates on a cloud-native infrastructure optimized for both training and serving foundation models. This flexibility allows for the deployment of models in various environments, including on-premises setups.</p> </li> </ul> <p>These components are integrated into a comprehensive platform that supports the entire lifecycle of AI model development, from initial creation to deployment and management, ensuring enterprises can leverage AI effectively across various business functions.</p>"},{"location":"watsonx.ai/watsonx/#watsonxai-walkthrough","title":"watsonx.ai walkthrough","text":"<p>In this document, you will learn how to implement generative AI use cases in watsonx.ai. watsonx.ai is an AI platform that supports both traditional machine learning applications and those leveraging Large Language Models (LLMs) for tasks such as generation, summarization, and classification.</p> <p>Note: LLMs are a type of foundation model. In IBM tools and documentation, the terms LLM and foundation models are used interchangeably.</p> <p></p> <p>Generative AI is a cutting-edge field in AI, enabling users to interact with models using natural language. A user sends requests (prompts) to a model, and the model generates a response. To an end user, generative AI may resemble a chatbot or a search engine, but its implementation differs significantly from legacy chatbots that rely on hardcoded business rules and search engines that use indexing.</p> <p>Generative AI uses Large Language Models (LLMs) to generate responses to prompts.</p> <p></p>"},{"location":"watsonx.ai/watsonx/#prompt-lab-in-watsonxai","title":"Prompt Lab in watsonx.ai","text":"<p>We will use the Prompt Lab in watsonx.ai to interact with LLMs included in the platform. Typically, users (prompt engineers or data scientists) have three goals in this phase of the LLM lifecycle:</p> <ul> <li>Find if LLMs can be used for the proposed use case</li> <li>Identify the best model and parameters</li> <li>Create prompts for the use case.</li> </ul>"},{"location":"watsonx.ai/watsonx/#step-1-login-and-create-a-project","title":"Step 1: Login and create a project","text":"<ol> <li>Log in to your IBM Cloud account.</li> <li>From the main menu in the top left corner select Projects -&gt; View All Projects.    </li> <li>Click on the New Project button. Select Empty Project and choose the project name.     </li> </ol>"},{"location":"watsonx.ai/watsonx/#step-2-associate-services-with-project","title":"Step 2: Associate Services with Project","text":"<ol> <li> <p>Switch to the Services and Integrations tab, then click Associate Service.    </p> </li> <li> <p>Select the displayed Machine Learning service and click Associate.    </p> </li> </ol>"},{"location":"watsonx.ai/watsonx/#step-3-create-new-assets","title":"Step 3: Create New Assets","text":"<ol> <li> <p>Switch to the Assets tab, then click the New asset button.    </p> </li> <li> <p>Click on the Experiment with foundation models\u2026 title.    </p> </li> </ol>"},{"location":"watsonx.ai/watsonx/#step-4-prompt-lab","title":"Step 4: Prompt Lab","text":"<ol> <li> <p>After the Prompt Lab UI opens, to start interacting with the LLM choose from one of the three options availabe:</p> </li> <li> <p>Chat</p> </li> <li>Structured</li> <li> <p>Freeform</p> </li> <li> <p>In the Chat view, you can chat with the foundational model. You start the chat by submitting a query in the text box as you can see in the image below. Each chat in the conversation builds off the information that was previously exchanged throughout the interaction. Before starting a chat session, you can adjust the model choice and parameter settings. This is similar to the chat interaction that you can have with watsonx Assistant.    </p> </li> <li> <p>The Structured view is designed to help new users create effective prompts. The text from the fields - Instruction and Examples - is sent to the model in a template format.</p> </li> <li> <p>Instruction: An instruction is an imperative statement for the model to follow (ex. Summarize the following article)</p> </li> <li>Examples: Add one or more pairs of examples (input AND output) to help the model learn. Providing a few examples of the input/output pair is called few-shot prompting.</li> <li>Test your prompt: In the Try area, you can test out your model and see the responses it will give.</li> </ol> <p></p> <ol> <li>The Freeform view is a good choice when you want to submit a structured input and know how to format the prompt. You can simply add your prompt in plain text in the large text box as seen in the image below. Your prompt text will be sent to the model exactly as you type it.</li> </ol> <p></p>"},{"location":"watsonx.ai/watsonx/#step-5-foundation-models","title":"Step 5: Foundation Models","text":"<ol> <li> <p>In each of these view, the first step is choosing a model.</p> </li> <li> <p>You can click on model -&gt; view all foundation models and you can select your desired model from the model catalog.     </p> </li> <li> <p>If you click on each of these models, you can see the model card which explains the details about the model and what tasks the model is good at. By reading the model card information, you can pick your model of choice.    </p> </li> <li> <p>Once you picked the model, then you can choose different prompt templates and experiment with them, or modify them to match to your needs.</p> </li> <li> <p>Click on model parameters icon in the top right corner. we can modify and try different model parameters and models to optimize it for your use case. If you would like to learn more about each input in the Model parameters panel, you can review documentation. You can change the Max tokens to <code>500</code>. When LLMs process instructions and generate output, they convert words to tokens (a sequence of characters). While there isn\u2019t a static ratio for letter to token conversion, we can use 10 words = 15 to 20 tokens as a rule of thumb for conversion. </p> </li> <li> <p>Working with LLMs requires experimentation and you can save your prompts, as a prompt template and use it later. In the Prompt Lab we can save the results of our experimentation with prompts</p> </li> <li> <p>As a notebook</p> </li> <li>As a prompt</li> <li>As a prompt session.</li> </ol> <p>If we save our experimentation as a prompt session, we will be able to access various prompts and the output that was generated. In the Prompt Lab, select Save work -&gt; Save as -&gt; Prompt session. For more information check out this documentation.</p>"}]}